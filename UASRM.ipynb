{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgOjXgE2KoCc"
      },
      "source": [
        "Todd Goldfarb\n",
        "\n",
        "tcgoldfarb@gmail.com\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTIO9hifP6Dc"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNiYDvBuJBnr",
        "outputId": "90f9e84b-ea36-4900-f8cb-fabe0e087464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.10.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "### Imports\n",
        "!pip install numpy matplotlib librosa pydub torch soundfile\n",
        "\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import soundfile\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as functional\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAXfyvs4QDIx"
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "### AUDIO/SPECTROGRAM RELATED OPERATIONS ###\n",
        "############################################\n",
        "\n",
        "### CONVERSION FUNCTIONS ###\n",
        "def ConvertWAVToArray(audioPath):\n",
        "  audio, sr = librosa.load(audioPath, sr=None)\n",
        "  return audio, sr\n",
        "\n",
        "def ConvertToTensor(np):\n",
        "  tensor = torch.from_numpy(np).float()\n",
        "  # ADD THE CHANNEL\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  return tensor\n",
        "\n",
        "def ConvertTensorToSpectrogram(tensor):\n",
        "  # NOTE IF ON GPU (PROB) NEED TO ADD .cpu()\n",
        "  spectrogram = tensor.squeeze().detach().numpy()\n",
        "  return spectrogram\n",
        "\n",
        "def ConvertArrayToSpectrogram(array):\n",
        "  # Compute STFT\n",
        "  stft = librosa.stft(array)\n",
        "\n",
        "  # Extract magnitude and phase\n",
        "  magnitude = np.abs(stft)\n",
        "  phase = np.angle(stft)\n",
        "\n",
        "  # Convert magnitude to decibel\n",
        "  spectrogram = librosa.amplitude_to_db(magnitude, ref=np.max)\n",
        "\n",
        "  return spectrogram, phase\n",
        "\n",
        "### OUTPUT THE SPECTROGRAM TO A WAV FILE WITH A SPECIFIED OUTPUT PATH ###\n",
        "def OutputSpectrogramToWAV(spectrogram_db, phase, sr, outputPath):\n",
        "    # Convert dB back to amplitude\n",
        "    spectrogram_amplitude = librosa.db_to_amplitude(spectrogram_db, ref=15.0)\n",
        "    print(type(spectrogram_amplitude), type(phase))\n",
        "    # Reconstruct the complex-valued STFT from magnitude and phase\n",
        "    stft_complex = spectrogram_amplitude * np.exp(1j * phase)\n",
        "\n",
        "    # Perform the inverse STFT\n",
        "    audio_reconstructed = librosa.istft(stft_complex)\n",
        "\n",
        "    # Write to WAV\n",
        "    soundfile.write(outputPath, audio_reconstructed, sr)\n",
        "    return\n",
        "\n",
        "### DAMAGES (REMOVES) AUDIO AT SPECIFIC TIME FRAME ###\n",
        "def DamageSpectrogram(spectrogram, sr, n_fft=2048, hop_length=512):\n",
        "\n",
        "    time_step = hop_length / sr\n",
        "    # Calculate the total duration of the audio in seconds\n",
        "    audio_duration = spectrogram.shape[1] * time_step\n",
        "\n",
        "    startSec = 2.25\n",
        "    endSec = 2.50\n",
        "\n",
        "    startCol = int(startSec / time_step)\n",
        "    endCol = int(endSec / time_step)\n",
        "\n",
        "    damagedSpectrogram = np.copy(spectrogram)\n",
        "\n",
        "    # Apply damage (set to zeros in this case)\n",
        "    damagedSpectrogram[:, startCol:endCol] = 0\n",
        "\n",
        "    return damagedSpectrogram, startSec, endSec\n",
        "\n",
        "def PlotSpectrogram(spectrogram, sr, isDamaged=False):\n",
        "  # PLOT SPECTROGRAM\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='log')\n",
        "  plt.colorbar(format='%+2.0f dB')\n",
        "  if isDamaged:\n",
        "    plt.title('Spectrogram (Broken Audio)')\n",
        "  else:\n",
        "    plt.title('Spectrogram (Clean Audio)')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJWhWM4jNX1q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "905c9acd-2a90-45ff-a809-a99ef5ac8339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-5e08ec26e763>:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sr = librosa.load(audioPath, sr=None)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset1.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'dataset1.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-e905a6633b44>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0maudioPathList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset1.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset2.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset3.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset4.wav\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0msamplesPerAudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mGeneratorDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscriminatorDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerateDatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioPathList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplesPerAudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-e905a6633b44>\u001b[0m in \u001b[0;36mGenerateDatasets\u001b[0;34m(audioPathList, samplesPerAudio)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0maudioPath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreparedAudioPathList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamplesPerAudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleanSpecTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdamagedSpecTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerateDataPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioPath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0;31m### GENERATOR DATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       GeneratorDataset.append([audioPath[1], # For output filePath\n",
            "\u001b[0;32m<ipython-input-29-e905a6633b44>\u001b[0m in \u001b[0;36mGenerateDataPoint\u001b[0;34m(audioPath)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m### GENERATES A FULL DATAPOINT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mGenerateDataPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mcleanArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvertWAVToArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m### CONVERT TO SPECTROGRAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-5e08ec26e763>\u001b[0m in \u001b[0;36mConvertWAVToArray\u001b[0;34m(audioPath)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### CONVERSION FUNCTIONS ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvertWAVToArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 )\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-119>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset1.wav'"
          ]
        }
      ],
      "source": [
        "##########################\n",
        "### DATASET GENERATION ###\n",
        "##########################\n",
        "\n",
        "## PREPARE AUDIO LIST\n",
        "def SegmentAudio(audioPathList):\n",
        "  os.makedirs(\"Audio_Inputs_Segmented\", exist_ok=True)\n",
        "\n",
        "  preparedAudioPathList = []\n",
        "  count = -1\n",
        "\n",
        "  for audioPath in enumerate(audioPathList):\n",
        "     # Load the audio file\n",
        "    audio, sr = librosa.load(audioPath[1], sr=None)\n",
        "\n",
        "    secPerChunk = 3.0\n",
        "    ## SECONDS PER CHUNK\n",
        "    samplesPerChunk = int(secPerChunk * sr)\n",
        "\n",
        "    # CALCULATE NUMBER OF CHUNKS\n",
        "    totalChunks = np.ceil(len(audio) / samplesPerChunk).astype(int) - 1\n",
        "    count += 1\n",
        "    for i in range(totalChunks):\n",
        "        startSample = i * samplesPerChunk\n",
        "        endSample = startSample + samplesPerChunk\n",
        "        chunk = audio[startSample:endSample]\n",
        "\n",
        "        # OUTPUT CHUNK\n",
        "        outputPath = os.path.join(\"Audio_Inputs_Segmented\", 'input_' + str(count) + '_' + str(i) + '.wav')\n",
        "        soundfile.write(outputPath, chunk, sr)\n",
        "        preparedAudioPathList.append(outputPath)\n",
        "\n",
        "  return preparedAudioPathList\n",
        "\n",
        "\n",
        "### GENERATES A FULL DATAPOINT\n",
        "def GenerateDataPoint(audioPath):\n",
        "  cleanArray, sr = ConvertWAVToArray(audioPath)\n",
        "\n",
        "  ### CONVERT TO SPECTROGRAM\n",
        "  cleanSpectrogram, phase = ConvertArrayToSpectrogram(cleanArray)\n",
        "  damagedSpectrogram, startSec, endSec = DamageSpectrogram(cleanSpectrogram, sr)\n",
        "\n",
        "  ### CONVERT ALL TO TENSORS\n",
        "  cleanSpecTensor = ConvertToTensor(cleanSpectrogram)\n",
        "  damagedSpecTensor = ConvertToTensor(damagedSpectrogram)\n",
        "\n",
        "  #PlotSpectrogram(cleanSpectrogram, sr)\n",
        "  #PlotSpectrogram(damagedSpectrogram, sr, True)\n",
        "\n",
        "  return sr, phase, cleanSpecTensor, damagedSpecTensor, startSec, endSec\n",
        "\n",
        "### GENERATES BOTH GENERATOR AND DISCRIMINATOR DATASETS\n",
        "### PASS IN A LIST OF AUDIOPATHS and A NUMBER OF SAMPLES PER AUDIO PIECE\n",
        "def GenerateDatasets(audioPathList, samplesPerAudio=1):\n",
        "\n",
        "  GeneratorDataset = []\n",
        "  DiscriminatorDataset = []\n",
        "\n",
        "  ## PREPARE THE audioPathList INTO 5 SECOND AUDIO CLIPS\n",
        "  #preparedAudioPathList = SegmentAudio(audioPathList)\n",
        "  # TEMPORARY TESTING\n",
        "  preparedAudioPathList = audioPathList\n",
        "\n",
        "  for audioPath in enumerate(preparedAudioPathList):\n",
        "    for i in range(samplesPerAudio):\n",
        "      sr, phase, cleanSpecTensor, damagedSpecTensor, startTime, endTime = GenerateDataPoint(audioPath[1])\n",
        "      ### GENERATOR DATASET\n",
        "      GeneratorDataset.append([audioPath[1], # For output filePath\n",
        "                               sr, # For converting back to WAV\n",
        "                               cleanSpecTensor, # Used for actualLoss\n",
        "                               damagedSpecTensor, # Used as contextInput\n",
        "                               startTime, # Used as a startTime input\n",
        "                               endTime, # Used as an endTime input\n",
        "                               phase]) # Used for WAV output\n",
        "      ### DISCRIMINATOR DATASET\n",
        "      DiscriminatorDataset.append([audioPath[1], # For output filePath\n",
        "                                   sr, # For converting back to WAV\n",
        "                                   cleanSpecTensor, # Used for realLoss\n",
        "                                   damagedSpecTensor, # Used for generating fake spectrogram for fakeLoss\n",
        "                                   startTime,\n",
        "                                   endTime,\n",
        "                                   phase]) # Used for WAV output\n",
        "\n",
        "  return GeneratorDataset, DiscriminatorDataset\n",
        "\n",
        "\n",
        "## THE AUDIO WILL BE CUT UP INTO 5 SECOND SEGMENTS\n",
        "## THE DAMAGE WILL OCCUR AT THE TIMESTAMP 2.25 - 2.75\n",
        "audioPathList = [\"dataset1.wav\", \"dataset2.wav\", \"dataset3.wav\", \"dataset4.wav\"]\n",
        "samplesPerAudio = 1\n",
        "GeneratorDataset, DiscriminatorDataset = GenerateDatasets(audioPathList, samplesPerAudio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R87kbngOZGuI"
      },
      "outputs": [],
      "source": [
        "### MODEL DEFINITIONS ###\n",
        "\n",
        "\n",
        "### Feature map way too big for 1 second of audio\n",
        "###w Output being stretched by stride? - MAYBE\n",
        "### Capping high and low values (LOW VALUES DONE, HIGH VALUES PROP NOT HELPFUL)\n",
        "### Batch normalization?\n",
        "### activation functions?\n",
        "## proper DB scaling?\n",
        "# Phase?\n",
        "# More data?\n",
        "## ADD PADDING INSTEAD OF INTERPOLATING (could be stretching out those values)\n",
        "## New loss criterion\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # ENCODER/DOWNSAMPLING\n",
        "        self.Encoder1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 3), stride=1, padding=1, padding_mode='replicate')\n",
        "        self.Encoder2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=2, padding=1, padding_mode='replicate')\n",
        "        self.Encoder3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), stride=2, padding=1, padding_mode='replicate')\n",
        "        self.Encoder4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3, 3), stride=2, padding=1, padding_mode='replicate')\n",
        "        self.Encoder5 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3), stride=2, padding=1, padding_mode='replicate')\n",
        "        self.Encoder6 = nn.Conv2d(in_channels=1024, out_channels=2048, kernel_size=(3, 3), stride=2, padding=1, padding_mode='replicate')\n",
        "        self.Encoder7 = nn.Conv2d(in_channels=2048, out_channels=4096, kernel_size=(3, 3), stride=2, padding=1, padding_mode='replicate')\n",
        "\n",
        "        # DECODER/UPSAMPLING\n",
        "        self.Decoder1 = nn.ConvTranspose2d(in_channels=4096, out_channels=2048, kernel_size=(3, 3), stride=2, padding=1)\n",
        "        self.Decoder2 = nn.ConvTranspose2d(in_channels=2048, out_channels=1024, kernel_size=(3, 3), stride=2, padding=1)\n",
        "        self.Decoder3 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=(3, 3), stride=2, padding=1)\n",
        "        self.Decoder4 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(3, 3), stride=2, padding=1)\n",
        "        self.Decoder5 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(3, 3), stride=2, padding=1)\n",
        "        self.Decoder6 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(3, 3), stride=2, padding=1)\n",
        "        self.Decoder7 = nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=(3, 3), stride=1, padding=1)\n",
        "\n",
        "\n",
        "        # SKIP CONNECTIONS\n",
        "        self.Skip64 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=1, padding=0, padding_mode='replicate')\n",
        "        self.Skip128 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=1, padding=0, padding_mode='replicate')\n",
        "        self.Skip256 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=0, padding_mode='replicate')\n",
        "        self.Skip512 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3), stride=1, padding=0, padding_mode='replicate')\n",
        "        self.Skip1024 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=1, padding=1, padding_mode='replicate')\n",
        "        self.Skip2048 = nn.Conv2d(in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=1, padding=1, padding_mode='replicate')\n",
        "\n",
        "    def forward(self, contextInput, startTime, endTime, sr):\n",
        "        # ENCODE\n",
        "        #print(contextInput.shape)\n",
        "        E1Output = (self.Encoder1(contextInput))\n",
        "        #print(E1Output.shape)\n",
        "        E2Output = (self.Encoder2(E1Output))\n",
        "        #print(E2Output.shape)\n",
        "        E3Output = (self.Encoder3(E2Output))\n",
        "        #print(E3Output.shape)\n",
        "        E4Output = (self.Encoder4(E3Output))\n",
        "        #print(E4Output.shape)\n",
        "        E5Output = (self.Encoder5(E4Output))\n",
        "        #print(E5Output.shape)\n",
        "        E6Output = (self.Encoder6(E5Output))\n",
        "        #print(E6Output.shape)\n",
        "        E7Output = (self.Encoder7(E6Output))\n",
        "        #print(E7Output.shape)\n",
        "\n",
        "        #DECODE (AND NO SKIP YET)\n",
        "        D1Input = functional.interpolate(self.Skip2048(E6Output), size=self.Decoder1(E7Output).shape[2:], mode='bilinear', align_corners=False)\n",
        "        D1Output = (self.Decoder1(E7Output) + D1Input)\n",
        "        #D1Output = (self.Decoder1(E7Output))\n",
        "\n",
        "        D2Input = functional.interpolate(self.Skip1024(E5Output), size=self.Decoder2(D1Output).shape[2:], mode='bilinear', align_corners=False)\n",
        "        D2Output = (self.Decoder2(D1Output) + D2Input)\n",
        "        #D2Output = (self.Decoder2(D1Output))\n",
        "\n",
        "        D3Input = functional.interpolate(self.Skip512(E4Output), size=self.Decoder3(D2Output).shape[2:], mode='bilinear', align_corners=False)\n",
        "        D3Output = (self.Decoder3(D2Output) + D3Input)\n",
        "        #D3Output = (self.Decoder3(D2Output))\n",
        "\n",
        "        D4Input = functional.interpolate(self.Skip256(E3Output), size=self.Decoder4(D3Output).shape[2:], mode='bilinear', align_corners=False)\n",
        "        D4Output = (self.Decoder4(D3Output) + D4Input)\n",
        "        #D4Output = (self.Decoder4(D3Output))\n",
        "\n",
        "        D5Input = functional.interpolate(self.Skip128(E2Output), size=self.Decoder5(D4Output).shape[2:], mode='bilinear', align_corners=False)\n",
        "        D5Output = (self.Decoder5(D4Output) + D5Input)\n",
        "        #D5Output = (self.Decoder5(D4Output))\n",
        "\n",
        "        D6Input = functional.interpolate(self.Skip64(E1Output), size=self.Decoder6(D5Output).shape[2:], mode='bilinear', align_corners=False)\n",
        "        D6Output = (self.Decoder6(D5Output) + D6Input)\n",
        "        #D6Output = (self.Decoder6(D5Output))\n",
        "\n",
        "        generatedChunk = (self.Decoder7(D6Output))\n",
        "        scaledOutput = generatedChunk\n",
        "\n",
        "        #output = functional.interpolate(generatedChunk, size=noiseChunk.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        ## SCALE THE OUTPUT BACK TO PROPER DB\n",
        "        #minDB = -80\n",
        "        #maxDB = 10\n",
        "        #scaledOutput = output * (((maxDB - minDB) / 2) + ((maxDB + minDB) / 2))\n",
        "\n",
        "        ## SPLICE THE PREDICTION BACK INTO THE ORIGINAL SPECTROGRAM\n",
        "        ## CREATING A \"HEALED\" SPECTROGRAM\n",
        "        hopLength = 512\n",
        "\n",
        "        timeStep = hopLength / sr\n",
        "\n",
        "        audio_duration = scaledOutput.shape[3] * timeStep\n",
        "        startCol = int(startTime / timeStep)\n",
        "        endCol = int(endTime / timeStep)\n",
        "\n",
        "        finalOutput = contextInput.clone()[:, 0:1, : :]\n",
        "        finalOutput[:, :, :, startCol:endCol] = scaledOutput[:, :, :, startCol:endCol]\n",
        "\n",
        "        #return scaledOutput\n",
        "        return finalOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNWOC-T1Zac6"
      },
      "outputs": [],
      "source": [
        "### TRAINING ###\n",
        "Generator = Generator()\n",
        "#Discriminator = Discriminator()\n",
        "\n",
        "### HYPER PARAMETERS\n",
        "batchSize = 1\n",
        "numWorkers = 2\n",
        "numEpochs = 100\n",
        "learningRate = 0.0002\n",
        "\n",
        "# LOSS AND OPTIMIZERS\n",
        "optimizerGenerator = optim.Adam(Generator.parameters(), lr=learningRate, betas=(0.5, 0.999))\n",
        "#optimizerDiscriminator = optim.Adam(Discriminator.parameters(), lr=learningRate, betas=(0.5, 0.999))\n",
        "\n",
        "# TRAINING LOOP\n",
        "DataloaderG = DataLoader(GeneratorDataset, batch_size=batchSize, shuffle=True, num_workers=numWorkers)\n",
        "### DataloaderG[i][0] is the audioPath\n",
        "### DataloaderG[i][1] is the sr (used as Input)\n",
        "### DataloaderG[i][2] is the cleanSpecTensor (Used for actualLoss)\n",
        "### DataloaderG[i][3] is the damagedSpecTensor (Used as Context Input)\n",
        "### DataloaderG[i][4] is the startTime input (Used as a startTime Input)\n",
        "### DataloaderG[i][5] is the endTime input (Used as an endTime Input)\n",
        "\n",
        "for epoch in range(numEpochs):\n",
        "  print(\"------------ \" + \"EPOCH: \" + str(epoch) + \" ------------\")\n",
        "  BCELoss = nn.BCELoss()\n",
        "  MSELoss = nn.MSELoss()\n",
        "\n",
        "  ### TRAIN GENERATOR ###\n",
        "  for GeneratorData in DataloaderG:\n",
        "    Generator.zero_grad()\n",
        "    genOutput = Generator.forward(GeneratorData[3],\n",
        "                                  GeneratorData[4],\n",
        "                                  GeneratorData[5],\n",
        "                                  GeneratorData[1])\n",
        "\n",
        "    ### THE GENERATED VS REAL ###\n",
        "    actualLoss = MSELoss(genOutput, GeneratorData[2])\n",
        "\n",
        "    actualWeight = 1\n",
        "    trueLoss = (actualLoss * actualWeight)\n",
        "    print(\"GENERATOR STEP: trueLoss = \")\n",
        "    print(trueLoss)\n",
        "    trueLoss.backward()\n",
        "\n",
        "    optimizerGenerator.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpokbS7w0Wrq"
      },
      "outputs": [],
      "source": [
        "### TESTING POST-TRAINING\n",
        "testURL = \"Audio_Inputs_Segmented/input_0_0.wav\"\n",
        "sr, phase, cleanSpecTensor, damagedSpecTensor, startTime, endTime = GenerateDataPoint(testURL)\n",
        "\n",
        "Generator.eval()\n",
        "with torch.no_grad():\n",
        "  output = Generator.forward(damagedSpecTensor.unsqueeze(0), startTime, endTime, sr)\n",
        "  output = torch.clamp(output, min=-80)\n",
        "\n",
        "print(output.shape)\n",
        "\n",
        "outputSpectrogram = ConvertTensorToSpectrogram(output)\n",
        "targetSpectrogram = ConvertTensorToSpectrogram(cleanSpecTensor)\n",
        "PlotSpectrogram(targetSpectrogram, sr)\n",
        "inputSpectrogram = ConvertTensorToSpectrogram(damagedSpecTensor[0:1, :, :].unsqueeze(0))\n",
        "PlotSpectrogram(inputSpectrogram, sr, True)\n",
        "\n",
        "\n",
        "PlotSpectrogram(outputSpectrogram, sr, True)\n",
        "print(outputSpectrogram.shape)\n",
        "print(type(outputSpectrogram))\n",
        "OutputSpectrogramToWAV(outputSpectrogram, phase, sr, \"Audio_Inputs_Segmented/input_0_0.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5CIoXTF3oaI"
      },
      "outputs": [],
      "source": [
        "### Accuracy Calculations\n",
        "\n",
        "originalArray = inputSpectrogram\n",
        "reconstructedArray = outputSpectrogram\n",
        "\n",
        "# ELEMENT-WISE COMPARISON\n",
        "comparison = originalArray == reconstructedArray\n",
        "\n",
        "# Count TRUE values\n",
        "correctElements = np.sum(comparison)\n",
        "\n",
        "totalElements = np.size(originalArray)\n",
        "\n",
        "accuracyPercentage = (correctElements / totalElements) * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracyPercentage}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}